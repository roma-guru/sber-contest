Описание структуры:

В папке [dockers](dockers/) лежат примеры Dockerfile, которые используются на сервере.

В папке [simple-baseline](simple-baseline/) лежит пример бейзлайна на основе простой эвристики ([Подробная инструкция](simple-baseline/Readme.md)).

Файл [squad.py](squad.py) содержит код для рассчета метрики для одной пары параграфа вопроса.

## Описание формата решения
Каждое решение должно быть оформлено в виде zip-архива, в корне которого должен быть metadata.json.
Пример:
`
{
  "image": "sberbank/sdsj-python",
  "entrypoint": "python3 predict.py"
}
`
В нем есть два обязательных поля `entrypoint` - команда для запуска внутри docker контейнера. `image` - образ докера, который будет использоваться для запуска контейнера. Указывать можно любые образы доступные на docker hub или те, которые лежат в папке [dockers](dockers/). Остальные файлы в архиве доступны на использование в процессе исполнения вашего решения.

## Ограничения
Каждому решению отводится ограниченное количество ресурсов.

Оперативной памяти доступно 8гб.

Размер распакованного архива не должен привышать 1гб и на размер упакованного архива такое же ограничение.

Доступно 2 cpu ядра.

Размер файла с предскзааниями не должен превышать 52 мегобайта (решение, в котором в качестве ответа подставляется полный параграф).

Ограничение на время исполнения равно 20 минутам (включая чтение своих моделей, данных и запись предсказания).

## Как прогонять решения без отправки в систему:
1. Разделить данные на трейн/валидейт: можно это сделать скриптом `python3 split_train.py path_to_train.csv`. В результате,  в этой же папке, где находится скрипт, создадутся два файла: `train_without_validate.csv`, `validate.csv`. Теперь обучаться будет на первом файле, а оценивать по второму.

2. Создаете новое решение. Снова обучаете модель, но уже с новыми признаками и сохраняете сопуствующие данные (модель предсказания и IDF-веса слов).

3. Чтобы прогнать решение можно запустить следующий скрипт: `python3 check_solution.py -t docker --submission_folder simple-baseline --data_file validate.csv`, данные скрипт запустит ваше решение наподобие того, как это работает на платформе: запустит ваше решение в докере(требуется установленный и запущенный докер, и ряд библиотек для питона(см. requirements.txt)) на файле `validate.csv`, решением данный скрипт считает все что находится в папке `simple-baseline` и будет запущен `predict.py` от туда.

Другие варианты запуска:
`python3 check_solution.py -t simple --submission_folder simple-baseline --data_file validate.csv` запустит ваше решение без докера.

`python3 check_solution.py -t simple --submission_file output_simple.zip --data_file validate.csv` запустит ваше решение без докера, решение будет взято из файла `output_simple.zip` (аналогичная опция работает и для запуска на докере).

По окончанию применения скрипта будет выведена строчка вида: `{'f1': 0.3361121166011774}`

## Для тех кто привык работать с `Jupyter Notebook`:
Чтобы каждый раз не копировать код из ноутбуков в `py`-файлы можно воспользоваться библиотекой dill, она в отличие от pickle позволяет сохранять не только данные и объекты, но и функции/классы/ламбды. Тем самым вы можете написать простой predict.py, который
1. импортирует все необходимые стандартные библиотеки, которые вы собираетесь использовать
2. загружает ваш код, который вы предварительно сериализовали: `code = dill.load(...)`
3. делает код доступным: `for obj_name in code: globals()[obj_name] = code[obj_name]`
4. далее следует обычный код загрузки тестовых данных, построению признаков и применению моделей, который будет меняться намного реже

URGENT: для работы выше описанного решения рекомендуется использовать одиннаковые версии питона, в противном случае могут быть проблемы с данным решением.
