{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "from nltk import word_tokenize\n",
    "import pymorphy2\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "morph = pymorphy2.MorphAnalyzer()\n",
    "\n",
    "def tag_word(s):\n",
    "    return morph.tag(s)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Токенизируем текст..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████| 38868/38868 [00:25<00:00, 1496.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "готово!\n"
     ]
    }
   ],
   "source": [
    "#FILENAME = \"c:/p/grammarphone/warandpeace\"\n",
    "FILENAME = r\"C:\\dataA\\servers\\A\\good_questions.txt\"\n",
    "\n",
    "with open(FILENAME, \"r\", encoding=\"utf8\") as f:\n",
    "    all_questions = f.readlines()\n",
    "\n",
    "tags_arr = []\n",
    "print(\"Токенизируем текст...\", end=\"\")\n",
    "tokenized_lines = [word_tokenize(curr_line) for curr_line in tqdm(all_questions)]\n",
    "print(\"готово!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 38868/38868 [05:22<00:00, 120.56it/s]\n"
     ]
    }
   ],
   "source": [
    "for line in tqdm(tokenized_lines):\n",
    "    tags = [str(morph.tag(curr_word)[0]) for curr_word in line]\n",
    "    tags_arr.append(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Длина и размер в памяти массива tags_arr 38868 321104\n"
     ]
    }
   ],
   "source": [
    "print(\"Длина и размер в памяти массива tags_arr\", len(tags_arr), sys.getsizeof(tags_arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import pickle, gzip\n",
    "#pickle.dump(tokenized_text, gzip.open( r\"o:\\datasets\\tolstoy_tokenized.gzip\", \"wb\" ))\n",
    "#pickle.dump(tags_arr, gzip.open( r\"o:\\datasets\\tolstoy_tagged.gzip\", \"wb\" ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle, gzip\n",
    "tokeninized_text = pickle.load( gzip.open(\"/media/artiom/Terminator/datasets/good_text_and_questions_tokenized.gzip\",\"rb\"))\n",
    "tags_arr = pickle.load( gzip.open(\"/media/artiom/Terminator/datasets/good_text_and_questions_tagged.gzip\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Создаём грамматические тройки\n",
      "Длина множества tags3_set: 300467\n",
      "В памяти tags3_set занимает 8388832\n"
     ]
    }
   ],
   "source": [
    "# Создаём грамматические тройки\n",
    "print(\"Создаём грамматические тройки\")\n",
    "tags3_set = set()\n",
    "for tagged_line in tags_arr:\n",
    "    array_length = len(tagged_line)\n",
    "    for x in range(2, array_length):\n",
    "        tag3 = tagged_line[x - 2] + tagged_line[x - 1] + tagged_line[x]\n",
    "        tags3_set.add(tag3)\n",
    "\n",
    "print(\"Длина множества tags3_set:\", len(tags3_set))\n",
    "print(\"В памяти tags3_set занимает\", sys.getsizeof(tags3_set))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Создаём грамматические четвёрки\n",
      "Длина множества tags4_set: 294261\n",
      "В памяти tags4_set занимает 8388832\n"
     ]
    }
   ],
   "source": [
    "# Создаём грамматические четвёрки\n",
    "print(\"Создаём грамматические четвёрки\")\n",
    "tags4_set = set()\n",
    "for tagged_line in tags_arr:\n",
    "    array_length = len(tagged_line)\n",
    "    for x in range(3, array_length):\n",
    "        tag4 = tagged_line[x - 2] + tagged_line[x - 2] + tagged_line[x - 1] + tagged_line[x]\n",
    "        tags4_set.add(tag4)\n",
    "\n",
    "print(\"Длина множества tags4_set:\", len(tags4_set))\n",
    "print(\"В памяти tags4_set занимает\", sys.getsizeof(tags4_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем на каком-нибудь тексте:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Попробуем на каком-нибудь тексте\n",
    "test_text_0 = \"С какого года Русское Царство перешло на летоисчисление от Рождества Христова и празднование Нового года 1 января, а не 1 сентября?\"\n",
    "test_text_1 = \"Из каких губок впервые были выделены токсины группы бромфакелинов?\"\n",
    "test_text_2 = \"Сколько уровней обозначаются l1, l2 и делаются попытки её драматизировать своё отношение к объёму?\"\n",
    "test_text_3 = \"Сколько и нормальной стоимостью понимается продажа товаров по цене производства, которая представляется возможным, сравнивают либо учитывают по торговле?\"\n",
    "test_text_4 = \"Кто издаёт указы согласно конституции боснии и распространена по миру и самок, поддерживаются гены альтруизма поддерживаются?\"\n",
    "test_text_5 = \"Как фэнтези и фэнтези с фэнтези как фэнтези и правила, противоречащие моим утверждениям, вы не игровые вселенные?\"\n",
    "test_text_6 = \"Когда эндлихер был чересчур кратко, а ощутимым недостатком работы?\"\n",
    "test_text_7 = \"Где определяется ценностями и базовыми представлениями, выстраивая их подхода затоплены у культуры?\"\n",
    "test_text_8 = \"Когда дебютный диск канадской группы Sum 41 — All Killer No Filler — достиг Top-10 местного хит-парада и, впоследствии, получил платиновый статус в США, также заняв верхнюю строчку чарта Billboard?\"\n",
    "test_text = test_text_8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "tokenized_test_text = word_tokenize(test_text)\n",
    "\n",
    "tags_array = []\n",
    "for x in tokenized_test_text:\n",
    "    tags = morph.tag(x)[0]\n",
    "    tags_array.append(str(tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "30 out of 32\n"
     ]
    }
   ],
   "source": [
    "# Проверяем вхождение кусочков текста в множество троек\n",
    "res_3 = []\n",
    "for i in range(2, len(tags_array)):\n",
    "    res = (tags_array[i - 2] + tags_array[i - 1] + tags_array[i]) in tags3_set\n",
    "    res_3.append(int(res))\n",
    "print(res_3)    \n",
    "print(sum(res_3), \"out of\", len(res_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "3 out of 31\n"
     ]
    }
   ],
   "source": [
    "# Проверяем вхождение кусочков текста в множество  ч е т в ё р о к\n",
    "res_4 = []\n",
    "for i in range(3, len(tags_array)):\n",
    "    res =  (tags_array[i - 3] + tags_array[i - 2] + tags_array[i - 1] + tags_array[i]) in tags4_set\n",
    "    res_4.append(int(res))\n",
    "print(res_4)    \n",
    "print(sum(res_4), \"out of\", len(res_4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tags5_set' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-fd85300381d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mres_5\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtags_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0;34m(\u001b[0m\u001b[0mtags_array\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtags_array\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtags_array\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtags_array\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtags_array\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtags5_set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mres_5\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres_5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tags5_set' is not defined"
     ]
    }
   ],
   "source": [
    "# Проверяем вхождение кусочков текста в множество  п я т ё р о к\n",
    "res_5 = []\n",
    "for i in range(4, len(tags_array)):\n",
    "    res =  (tags_array[i - 4] + tags_array[i - 3] + tags_array[i - 2] + tags_array[i - 1] + tags_array[i]) in tags5_set\n",
    "    res_5.append(int(res))\n",
    "print(res_5)    \n",
    "print(sum(res_5), \"out of\", len(res_5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0]\n",
      "0 out of 6\n"
     ]
    }
   ],
   "source": [
    "# Проверяем вхождение кусочков текста в множество  п я т ё р о к\n",
    "res_6 = []\n",
    "for i in range(5, len(tags_array)):\n",
    "    res = (tags_array[i - 5] + tags_array[i - 4] + tags_array[i - 3] + tags_array[i - 2] + tags_array[i - 1] + tags_array[i]) in tags6_set\n",
    "    res_6.append(int(res))\n",
    "print(res_6)\n",
    "print(sum(res_6), \"out of\", len(res_6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
